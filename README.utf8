>Notes added by Lincoln A Baxter (lab@lincolnbaxter.com) after
completing unicode (utf8) enhancements to DBD-Oracle.

For perl version 5.8 or later, and Oracle version 9.2 or
later, Unicode support has been added with the following
restrictions:

1. Only NCHAR and NVARCHAR columns are supported
   
2. The database national characterset MUST be UTF8.  Most 
Oracle database init scripts I have seen default the National
Character Set to AL16UTF16 which does NOT work.  You've been
warned.

3. Data to be inserted or updated into these columns must
be bound with the csform=>SQLCS_NCHAR attribute
as follows:

   use DBD::Oracle qw( SQLCS_NCHAR );
   $sth->bind_param(1, $value, { ora_csform =>SQLCS_NCHAR }); 

or

   use DBD::Oracle qw( SQLCS_NCHAR );
   $dbh->{ora_ph_csform} = 2;	# default all future ph to SQLCS_NCHAR

4.  NLS_LANG must be set, and MUST end with .UTF8

See the t/22nchar_utf8.t test for an example.

The modifications to support the above, also make it 
possible to possible to insert and extract 8 bit
characters into NCHAR columns in any valid NCHAR column, with
NLS_LANG ending with other popular 8 bit character sets like:

   .WE8ISO8859P1 and .WE8MSWIN1252

See the t/21char.t test for an example.

The UTF8 note below, refers to the original UFT8 work done in 2000
This was mainly implemented for LOB CLOB column types when oracle
8i was the current Oracle version. It HARD set UTF8 logic based on 
an examination of NLS_LANG, as apposed to asking Oracle through the
OCI api (which may not have existed at the time)  

Please note, that it appears that the t/30long.t test
is broken when NLS_LANG is set to a MULTI byte character set. So I am
quite confused about whether this code is even close to right, but I 
don't want to tear into it, for fear a breaking some existing app.
I would prefer someone more familiar with this piece look at this. 
I suspect that today, it would better be done with NCLOB columns.


>From Perl 5.6.0 onwards DBD::Oracle supports UTF8 as local
character set (using OCI8). Thus, when the environment 
variable NLS_LANG ends with "utf8", DBD::Oracle marks Perl 
strings as unicode (when multibyte characters are present). 
This affects the handling of CHAR/VARCHARx columns and 
LONGs/CLOBs.

Multibyte chars in Perl 5.6.0:

Perl 5.6.0 switches to character semantics (as compared to
byte) for multibyte strings. According to Perl documentation
this is done transparently to Perl scripts - all builtin
operators know about it. DBD::Oracle tries to preserve this
transparency as far as Oracle allows this (see below).

As a consequence, "LongReadLen" now counts characters and
not bytes when dealing with LONG/CLOB values. Selected LONGs
and CLOBs will return at most LongReadLen chars, but may
contain a multiple of that in actual bytes.

blob_read issued on CLOBs will also use character semantics.
You have to take extra precautions when using such strings
in a byte-size context, for example a fixed size field in
a protocol message. This is not specific to DBD::Oracle as
such, but be warned.

You need patches at least up to 6090 for Perl 5.6.0 for utf8
to work with DBD::Oracle. (For WinUsers: ActiveState build 
beyond 613 will probably do).


Multibyte chars in Oracle 8(i)

CHAR/VARCHAR and friends count size in bytes, not characters.
If you have a Oracle database created with character set utf8
and insert a string with 10 characters into a VARCHAR2(10)
column, this will only work if the string is 10 bytes long.
If the string is longer, it will fail (and report and error). 
This behaviour is inherent to Oracle/OCI and not influenced 
by DBD::Oracle.

This is then the place where transparency of utf8 breaks. If
you want to check your parameter lengths before insert, you 
have to switch Perl to bytes semantics (see "use bytes" in
Perl documentation).



2000-05-09, Stefan Eissing (se@acm.org)
